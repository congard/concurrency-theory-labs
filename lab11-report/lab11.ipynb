{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treść zadania\n",
    "\n",
    "Dane są:\n",
    "\n",
    "1. Alfabet $A$, w którym każda litera oznacza akcję.\n",
    "2. Relacja niezależności $I$, oznaczająca które akcje są niezależne (przemienne, tzn. można je wykonać w\n",
    "   dowolnej kolejności i nie zmienia to wyniku końcowego).\n",
    "3. Słowo $w$ oznaczające przykładowe wykonanie sekwencji akcji.\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "Napisz program w dowolnym języku, który:\n",
    "\n",
    "1. Wyznacza relację zależności $D$\n",
    "2. Wyznacza ślad $[w]$ względem relacji $I$\n",
    "3. Wyznacza postać normalną Foaty $FNF([w])$ śladu $[w]$\n",
    "4. Wyznacza graf zależności dla słowa $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp\n",
    "\n",
    "Wstęp teoretyczny, m.in opisy wykorzystanych algorytmów, można znaleźć w sprawozdaniu z laboratorium 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązanie\n",
    "\n",
    "W celu rozwiązania tego zadania zostanie użyty język Python 3.11.6. Również została wykorzystana biblioteka\n",
    "`pandas 2.1.3` w celu wypisywania niektórych wyników w postaci tabeli.\n",
    "Opis poszczególnych funkcji tego rozwiązania znajduje się poniżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Sequence\n",
    "import pandas as pd\n",
    "\n",
    "MARKER = '*'\n",
    "\n",
    "RelationIt = Iterable[tuple[str, str]]\n",
    "\n",
    "Stack = list[str]\n",
    "MultiStack = dict[str, Stack]\n",
    "Graph = list[list[int]]\n",
    "\n",
    "\n",
    "def stack_empty(A: Iterable[str]) -> MultiStack:\n",
    "    return dict([(c, []) for c in A])\n",
    "\n",
    "\n",
    "def stack_print(s: MultiStack):\n",
    "    df = pd.DataFrame.from_dict(s, orient=\"index\").transpose()\n",
    "    df.replace(to_replace=[None], value=' ', inplace=True)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "def stack_init(\n",
    "        word: Iterable[str] | str,\n",
    "        A: Iterable[str],\n",
    "        D: RelationIt,\n",
    "        verbose: bool = False) -> MultiStack:\n",
    "\n",
    "    # construct stack\n",
    "    stack = stack_empty(A)\n",
    "\n",
    "    # fill stack\n",
    "    for curr_action in reversed(word):\n",
    "        stack[curr_action].append(curr_action)\n",
    "\n",
    "        for action in A:\n",
    "            if action == curr_action:\n",
    "                continue\n",
    "\n",
    "            if (curr_action, action) in D:\n",
    "                # dependent, non commutative\n",
    "                stack[action].append(MARKER)\n",
    "            \n",
    "            if verbose:\n",
    "                stack_print(stack)\n",
    "                print()\n",
    "\n",
    "    return stack\n",
    "\n",
    "\n",
    "def stack_is_empty(s: MultiStack) -> bool:\n",
    "    for k in s:\n",
    "        if len(s[k]) > 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def stack_top(stack: MultiStack, pop: bool = False) -> list[str]:\n",
    "    top = []\n",
    "\n",
    "    for action in stack:\n",
    "        s = stack[action]\n",
    "\n",
    "        if len(s) > 0 and s[-1] != MARKER:\n",
    "            top.append(s.pop() if pop else s[-1])\n",
    "\n",
    "    return top\n",
    "\n",
    "\n",
    "def stack_remove_markers(\n",
    "        stack: MultiStack,\n",
    "        D: RelationIt,\n",
    "        top: list[str]) -> list[str]:\n",
    "    \n",
    "    popped = []\n",
    "    \n",
    "    for action in stack:\n",
    "        for top_action in top:\n",
    "            if action == top_action:\n",
    "                continue\n",
    "\n",
    "            if (top_action, action) in D:\n",
    "                s = stack[action]\n",
    "\n",
    "                if len(s) > 0 and s[-1] == MARKER:\n",
    "                    s.pop()  # pop marker\n",
    "                    popped.append(action)\n",
    "\n",
    "    return popped\n",
    "\n",
    "\n",
    "def stack_copy(stack: MultiStack) -> MultiStack:\n",
    "    return MultiStack([(k, stack[k].copy()) for k in stack])\n",
    "\n",
    "\n",
    "def graph_path_exists(graph: Graph, src: int, dst: int) -> bool:\n",
    "    class VertexInfo:\n",
    "        def __init__(self, vtime: int = -1, ptime: int = -1, parent: int = None):\n",
    "            self.vtime = vtime  # visited time\n",
    "            self.ptime = ptime  # processed time\n",
    "            self.parent = parent\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"[vtime={}, ptime={}, parent={}]\".format(self.vtime, self.ptime, self.parent)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return self.__str__()\n",
    "\n",
    "    def dfs(g: Graph, start: int):\n",
    "        n = len(g)\n",
    "        info = [VertexInfo() for _ in range(n)]\n",
    "        time = 0\n",
    "\n",
    "        def visit(u: int):\n",
    "            nonlocal time\n",
    "            time += 1\n",
    "\n",
    "            info[u].vtime = time  # wierzchołek został odwiedzony / czas odwiedzenia\n",
    "\n",
    "            for v in g[u]:\n",
    "                if info[v].vtime == -1:\n",
    "                    info[v].parent = u\n",
    "                    visit(v)\n",
    "\n",
    "            time += 1\n",
    "\n",
    "            info[u].ptime = time  # wierzchołek został przetworzony / czas przetworzenia\n",
    "\n",
    "        visit(start)\n",
    "\n",
    "        return info\n",
    "\n",
    "    inf = dfs(graph, src)\n",
    "\n",
    "    return inf[dst].vtime != -1\n",
    "\n",
    "\n",
    "def graph_add_edge(graph: Graph, src: int, dst: int):\n",
    "    graph[src].append(dst)\n",
    "\n",
    "\n",
    "# Foata Normal Form\n",
    "def fnf(\n",
    "        stack: MultiStack,\n",
    "        D: RelationIt,\n",
    "        verbose: bool = False) -> list[list[str]]:\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=== FNF ===\")\n",
    "    \n",
    "    # To get the Foata normal form we take within a loop the set formed by\n",
    "    # letters being on the top of stacks; arranging the letters in the lexicographic\n",
    "    # order yields a step. As previously we pop the corresponding markers. Again\n",
    "    # this loop is repeated until all stacks are empty.\n",
    "    \n",
    "    stack_fnf = stack_copy(stack)\n",
    "\n",
    "    fnf: list[list[str]] = []\n",
    "\n",
    "    while not stack_is_empty(stack_fnf):\n",
    "        if verbose:\n",
    "            stack_print(stack_fnf)\n",
    "\n",
    "        # step 1: construct top\n",
    "        top = stack_top(stack_fnf, pop=True)\n",
    "\n",
    "        # step 2: remove markers for non-commutative actions\n",
    "        removed = stack_remove_markers(stack_fnf, D, top)\n",
    "\n",
    "        fnf.append(sorted(top))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Popped top:\", top)\n",
    "            print(\"Removed markers:\", removed)\n",
    "            print()\n",
    "\n",
    "    return fnf\n",
    "\n",
    "\n",
    "# Lexicographic Normal Form\n",
    "def lnf(\n",
    "        stack: MultiStack,\n",
    "        D: RelationIt,\n",
    "        verbose: bool = False) -> list[str]:\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=== LNF ===\")\n",
    "    \n",
    "    # To get the lexicographic normal form: it suffices to take among the letters\n",
    "    # being on the top of some stack that letter a being minimal with respect\n",
    "    # to the given lexicographic ordering. We pop a marker on each stack corre-\n",
    "    # sponding to a letter b (b != a) which does not commute with a. We repeat\n",
    "    # this loop until all stacks are empty.\n",
    "\n",
    "    stack_norm = stack_copy(stack)\n",
    "\n",
    "    norm: list[str] = []\n",
    "\n",
    "    while not stack_is_empty(stack_norm):\n",
    "        if verbose:\n",
    "            stack_print(stack_norm)\n",
    "\n",
    "        # step 1: construct top\n",
    "        top = stack_top(stack_norm, pop=False)\n",
    "\n",
    "        # step 2: select minimal action and pop it\n",
    "        min_action = min(top)\n",
    "        stack_norm[min_action].pop()\n",
    "\n",
    "        # step 3: remove markers for non-commutative actions\n",
    "        removed = stack_remove_markers(stack_norm, D, [min_action])\n",
    "\n",
    "        norm.append(min_action)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Popped action:\", min_action)\n",
    "            print(\"Removed markers:\", removed)\n",
    "            print()\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def build_dot_graph(\n",
    "        word: Sequence[str] | str,\n",
    "        D: RelationIt) -> str:\n",
    "    \n",
    "    n = len(word)\n",
    "    graph: Graph = [[] for _ in range(n)]\n",
    "    \n",
    "    for dst in range(1, n):\n",
    "        d_label = word[dst]\n",
    "\n",
    "        for src in reversed(range(dst)):\n",
    "            s_label = word[src]\n",
    "\n",
    "            if (d_label, s_label) in D and not graph_path_exists(graph, src, dst):\n",
    "                graph_add_edge(graph, src, dst)\n",
    "    \n",
    "    # generate dot graph\n",
    "    dot = \"\"\n",
    "\n",
    "    for parent, children in enumerate(graph):\n",
    "        for child in children:\n",
    "            dot += f\"\\t{parent + 1} -> {child + 1}\\n\"\n",
    "\n",
    "    for i in range(n):\n",
    "        dot += f\"\\t{i + 1}[label={word[i]}]\\n\"\n",
    "\n",
    "    return f\"digraph g {{\\n{dot}}}\"\n",
    "\n",
    "\n",
    "def print_summary(\n",
    "        A: Iterable[str],\n",
    "        I: RelationIt, \n",
    "        w: str,\n",
    "        verbose: bool = False) -> None:\n",
    "    \n",
    "    # construct D set\n",
    "    D: set[tuple[str, str]] = set()\n",
    "\n",
    "    for p1 in A:\n",
    "        for p2 in A:\n",
    "            pair = (p1, p2)\n",
    "\n",
    "            if pair not in I:\n",
    "                D.add(pair)\n",
    "\n",
    "    # print D\n",
    "    print(f\"D = {sorted(D)}\")\n",
    "\n",
    "    stack = stack_init(w, A, D, verbose)\n",
    "\n",
    "    # calc FNF\n",
    "    print(f\"FNF = {fnf(stack, D, verbose)}\")\n",
    "\n",
    "    # calc lexicographic normal form\n",
    "    print(f\"LNF = {lnf(stack, D, verbose)}\")\n",
    "\n",
    "    print(build_dot_graph(w, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testowanie dla przykładowych danych testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = [('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'b'), ('b', 'd'), ('c', 'a'), ('c', 'c'), ('c', 'd'), ('d', 'b'), ('d', 'c'), ('d', 'd')]\n",
      "FNF = [['b'], ['a', 'd'], ['a'], ['b', 'c']]\n",
      "LNF = ['b', 'a', 'a', 'd', 'b', 'c']\n",
      "digraph g {\n",
      "\t1 -> 2\n",
      "\t1 -> 3\n",
      "\t2 -> 4\n",
      "\t3 -> 5\n",
      "\t3 -> 6\n",
      "\t4 -> 5\n",
      "\t4 -> 6\n",
      "\t1[label=b]\n",
      "\t2[label=a]\n",
      "\t3[label=d]\n",
      "\t4[label=a]\n",
      "\t5[label=c]\n",
      "\t6[label=b]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_summary(\n",
    "    A=['a', 'b', 'c', 'd'],\n",
    "    I={('a', 'd'), ('d', 'a'), ('b', 'c'), ('c', 'b')},\n",
    "    w=\"badacb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = [('a', 'a'), ('a', 'b'), ('a', 'c'), ('a', 'e'), ('a', 'f'), ('b', 'a'), ('b', 'b'), ('b', 'c'), ('b', 'd'), ('b', 'f'), ('c', 'a'), ('c', 'b'), ('c', 'c'), ('c', 'e'), ('d', 'b'), ('d', 'd'), ('d', 'e'), ('d', 'f'), ('e', 'a'), ('e', 'c'), ('e', 'd'), ('e', 'e'), ('e', 'f'), ('f', 'a'), ('f', 'b'), ('f', 'd'), ('f', 'e'), ('f', 'f')]\n",
      "FNF = [['a', 'd'], ['c', 'f'], ['c'], ['b', 'e'], ['b']]\n",
      "LNF = ['a', 'c', 'c', 'd', 'f', 'b', 'b', 'e']\n",
      "digraph g {\n",
      "\t1 -> 2\n",
      "\t1 -> 5\n",
      "\t2 -> 4\n",
      "\t3 -> 5\n",
      "\t4 -> 6\n",
      "\t4 -> 8\n",
      "\t5 -> 6\n",
      "\t5 -> 8\n",
      "\t6 -> 7\n",
      "\t1[label=a]\n",
      "\t2[label=c]\n",
      "\t3[label=d]\n",
      "\t4[label=c]\n",
      "\t5[label=f]\n",
      "\t6[label=b]\n",
      "\t7[label=b]\n",
      "\t8[label=e]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_summary(\n",
    "    A=['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    I={('a', 'd'), ('d', 'a'), ('b', 'e'), ('e', 'b'), ('c', 'd'), ('d', 'c'), ('c', 'f'), ('f', 'c')},\n",
    "    w=\"acdcfbbe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = [('a', 'a'), ('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'b'), ('c', 'a'), ('c', 'c')]\n",
      "FNF = [['a'], ['b'], ['a'], ['b'], ['a'], ['b', 'c'], ['b'], ['a']]\n",
      "LNF = ['a', 'b', 'a', 'b', 'a', 'b', 'b', 'c', 'a']\n",
      "digraph g {\n",
      "\t1 -> 2\n",
      "\t2 -> 3\n",
      "\t3 -> 4\n",
      "\t4 -> 5\n",
      "\t5 -> 6\n",
      "\t5 -> 8\n",
      "\t6 -> 7\n",
      "\t7 -> 9\n",
      "\t8 -> 9\n",
      "\t1[label=a]\n",
      "\t2[label=b]\n",
      "\t3[label=a]\n",
      "\t4[label=b]\n",
      "\t5[label=a]\n",
      "\t6[label=b]\n",
      "\t7[label=b]\n",
      "\t8[label=c]\n",
      "\t9[label=a]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_summary(\n",
    "    A=['a', 'b', 'c'],\n",
    "    I={('b', 'c'), ('c', 'b')},\n",
    "    w=\"abababbca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opis rozwiązania\n",
    "\n",
    "- Funkcje służące do zarządzania stosem\n",
    "  - `stack_empty` tworzy pusty zbiór stosów dla podanego alfabetu `A`\n",
    "  - `stack_print` wypisuje podany zbiór stosów `s`\n",
    "  - `stack_init` tworzy zbiór stosów dla danego słowa `word`, alfabetu `A` oraz relacji zależności `D`\n",
    "  - `stack_is_empty` sprawdza, czy zbiór stosów jest pusty. Zbiór stosów jest pusty wtedy i tylko wtedy, gdy wszystkie\n",
    "    stosy w nim zawarte są puste\n",
    "  - `stack_top` zwraca elementy z wierzchu stosów podanego zbioru stosów `stack`. Jeżeli `pop` jest ustawione na `True`,\n",
    "    usuwa te elementy ze stosów\n",
    "  - `stack_remove_markers` usuwa markery ze stosów, które są zależne od elementów listy `top` względem relacji zależności `D`\n",
    "  - `stack_copy` tworzy tzw. deep copy podanego zbioru stosów `stack`\n",
    "\n",
    "- Funkcje służące do zarządzania grafem\n",
    "  - `graph_path_exists` zwraca `True`, jeżeli w grafie `graph` istnieje ścieżka między wierzchołkiem o indeksie `src` a `dst`\n",
    "    ($src \\rightarrow ... \\rightarrow dst$)\n",
    "  - `graph_add_edge` dodaje krawędź skierowaną w grafie `graph` między wierzchołkiem o indeksie `src` a `dst` ($src \\rightarrow dst$)\n",
    "  \n",
    "- Funkcje służące do wyznaczania postaci normalnych\n",
    "  - `fnf` służy do wyznaczania postaci normalnej Foaty (FNF)\n",
    "  - `lnf` służy do wyznaczania leksykograficznej postaci normalnej (LNF)\n",
    "\n",
    "- Funkcja `build_dot_graph` służy do tworzenia grafu zależności Diekerta w formacie DOT. Do sprawdzenia czy istnieje\n",
    "  ścieżka między danymi wierzchołkami, został uzyty algorytm DFS\n",
    "\n",
    "- Funkcja `print_summary` służy do wypisywania wszystkich informacji dt. słowa `w` nad alfabetem `A` względem relacji\n",
    "  niezależności `I`. Funkcja ta wypisze następujące informacje:\n",
    "\n",
    "  - Relację zależności $D$\n",
    "  - Postać normalną Foaty $FNF$\n",
    "  - Leksykograficzną postać normalną $LNF$\n",
    "  - Graf w formacie DOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "Oprócz wniosków z laboratorium 10, można dodać następujące dodatkowe wnioski:\n",
    "\n",
    "- **Relacja zależności** $D$ jest dopełnieniem relacji niezależności $I$, tzn. $D = A × A ∖ I$, $D = \\bar{I}$. Oznacza to,\n",
    "  że dwie akcje są zależne, jeśli nie są niezależne.\n",
    "\n",
    "- **Graf zależności dla słowa** $w$ jest grafem skierowanym, w którym wierzchołki są akcjami z $w$, a krawędzie są relacją\n",
    "  zależności $D$. Oznacza to, że istnieje krawędź z $a$ do $b$, jeśli $a$ i $b$ są zależne i $a$ występuje przed $b$ w słowie $w$.\n",
    "\n",
    "- **Algorytm DFS** (ang. Depth First Search) służy do przechodzenia lub przeszukiwania drzewa lub grafu. Został użyty w celu\n",
    "  sprawdzenia, czy istnieje ścieżka między poszczególnymi wierzchołkami.\n",
    "\n",
    "- **DOT** jest językiem opisu grafów, opracowanym w ramach projektu Graphviz. Służy do definiowania wierzchołków, krawędzi,\n",
    "  grafów, podgrafów i klastrów za pomocą prostych reguł składniowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografia\n",
    "\n",
    "1. Materiały do laboratorium 10, dr inż. Włodzimierz Funika:\\\n",
    "   [https://home.agh.edu.pl/~funika/tw/lab-trace/](https://home.agh.edu.pl/~funika/tw/lab-trace/)\n",
    "\n",
    "2. Materiały do laboratorium 11, dr inż. Włodzimierz Funika:\\\n",
    "   [https://home.agh.edu.pl/~funika/tw/lab-trace2/](https://home.agh.edu.pl/~funika/tw/lab-trace2/)\n",
    "\n",
    "3. Trace Theory, Volker Diekert, Anca Muscholl:\\\n",
    "   [http://www2.informatik.uni-stuttgart.de/fmi/ti/veroeffentlichungen/pdffiles/DiekertMuscholl2011.pdf](http://www2.informatik.uni-stuttgart.de/fmi/ti/veroeffentlichungen/pdffiles/DiekertMuscholl2011.pdf)\n",
    "\n",
    "4. Partial Commutation and Traces, Volker Diekert, Yves Métivier:\\\n",
    "   [https://www.researchgate.net/publication/280851316_Partial_Commutation_and_Traces](https://www.researchgate.net/publication/280851316_Partial_Commutation_and_Traces)\n",
    "\n",
    "5. A Foata Normal Form And Its Application For The Purpose Of Accel­erating Computations By A Multi-GPU, Ahmet A. Husainov:\\\n",
    "   [https://www.researchgate.net/publication/283389280_A_FOATA_NORMAL_FORM_AND_ITS_APPLICATION_FOR_THE_PURPOSE_OF_ACCEL-ERATING_COMPUTATIONS_BY_A_MULTI-GPU](https://www.researchgate.net/publication/283389280_A_FOATA_NORMAL_FORM_AND_ITS_APPLICATION_FOR_THE_PURPOSE_OF_ACCEL-ERATING_COMPUTATIONS_BY_A_MULTI-GPU)\n",
    "\n",
    "6. Depth-first search, Wikipedia:\\\n",
    "   [https://en.wikipedia.org/wiki/Depth-first_search](https://en.wikipedia.org/wiki/Depth-first_search)\n",
    "\n",
    "7. DOT (graph description language), Wikipedia:\\\n",
    "   [https://en.wikipedia.org/wiki/DOT_(graph_description_language)](https://en.wikipedia.org/wiki/DOT_(graph_description_language))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csvenv",
   "language": "python",
   "name": "csvenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
